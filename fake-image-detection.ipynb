{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.setrecursionlimit(15000)\nimport torch\nimport torch.nn.functional as F\nfrom torch import nn\nimport torch.backends.cudnn as cudnn\nfrom torch.autograd import Variable\nimport torchvision.models as models\n\nNO_CAPS=10\n\nclass StatsNet(nn.Module):\n    def __init__(self):\n        super(StatsNet, self).__init__()\n\n    def forward(self, x):\n        x = x.view(x.data.shape[0], x.data.shape[1], x.data.shape[2]*x.data.shape[3])\n\n        mean = torch.mean(x, 2)\n        std = torch.std(x, 2)\n\n        return torch.stack((mean, std), dim=1)\n\nclass View(nn.Module):\n    def __init__(self, *shape):\n        super(View, self).__init__()\n        self.shape = shape\n\n    def forward(self, input):\n        return input.view(self.shape)\n\n\nclass VggExtractor(nn.Module):\n    def __init__(self, train=False):\n        super(VggExtractor, self).__init__()\n\n        self.vgg_1 = self.Vgg(models.vgg19(pretrained=True), 0, 18)\n        if train:\n            self.vgg_1.train(mode=True)\n            self.freeze_gradient()\n        else:\n            self.vgg_1.eval()\n\n    def Vgg(self, vgg, begin, end):\n        features = nn.Sequential(*list(vgg.features.children())[begin:(end+1)])\n        return features\n\n    def freeze_gradient(self, begin=0, end=9):\n        for i in range(begin, end+1):\n            self.vgg_1[i].requires_grad = False\n\n    def forward(self, input):\n        return self.vgg_1(input)\n\nclass FeatureExtractor(nn.Module):\n    def __init__(self):\n        super(FeatureExtractor, self).__init__()\n\n        self.capsules = nn.ModuleList([\n            nn.Sequential(\n                nn.Conv2d(256, 64, kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm2d(64),\n                nn.ReLU(),\n                nn.Conv2d(64, 16, kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm2d(16),\n                nn.ReLU(),\n                StatsNet(),\n\n                nn.Conv1d(2, 8, kernel_size=5, stride=2, padding=2),\n                nn.BatchNorm1d(8),\n                nn.Conv1d(8, 1, kernel_size=3, stride=1, padding=1),\n                nn.BatchNorm1d(1),\n                View(-1, 8),\n                )\n                for _ in range(NO_CAPS)]\n        )\n\n    def squash(self, tensor, dim):\n        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n        scale = squared_norm / (1 + squared_norm)\n        return scale * tensor / (torch.sqrt(squared_norm))\n\n    def forward(self, x):\n        # outputs = [capsule(x.detach()) for capsule in self.capsules]\n        # outputs = [capsule(x.clone()) for capsule in self.capsules]\n        outputs = [capsule(x) for capsule in self.capsules]\n        output = torch.stack(outputs, dim=-1)\n\n        return self.squash(output, dim=-1)\n\nclass RoutingLayer(nn.Module):\n    def __init__(self, gpu_id, num_input_capsules, num_output_capsules, data_in, data_out, num_iterations):\n        super(RoutingLayer, self).__init__()\n\n        self.gpu_id = gpu_id\n        self.num_iterations = num_iterations\n        self.route_weights = nn.Parameter(torch.randn(num_output_capsules, num_input_capsules, data_out, data_in))\n\n\n    def squash(self, tensor, dim):\n        squared_norm = (tensor ** 2).sum(dim=dim, keepdim=True)\n        scale = squared_norm / (1 + squared_norm)\n        return scale * tensor / (torch.sqrt(squared_norm))\n\n    def forward(self, x, random, dropout):\n        # x[b, data, in_caps]\n\n        x = x.transpose(2, 1)\n        # x[b, in_caps, data]\n\n        if random:\n            noise = Variable(0.01*torch.randn(*self.route_weights.size()))\n            if self.gpu_id >= 0:\n                noise = noise.cuda(self.gpu_id)\n            route_weights = self.route_weights + noise\n        else:\n            route_weights = self.route_weights\n\n        priors = route_weights[:, None, :, :, :] @ x[None, :, :, :, None]\n\n        # route_weights [out_caps , 1 , in_caps , data_out , data_in]\n        # x             [   1     , b , in_caps , data_in ,    1    ]\n        # priors        [out_caps , b , in_caps , data_out,    1    ]\n\n        priors = priors.transpose(1, 0)\n        # priors[b, out_caps, in_caps, data_out, 1]\n\n        if dropout > 0.0:\n            drop = Variable(torch.FloatTensor(*priors.size()).bernoulli(1.0- dropout))\n            if self.gpu_id >= 0:\n                drop = drop.cuda(self.gpu_id)\n            priors = priors * drop\n            \n\n        logits = Variable(torch.zeros(*priors.size()))\n        # logits[b, out_caps, in_caps, data_out, 1]\n\n        if self.gpu_id >= 0:\n            logits = logits.cuda(self.gpu_id)\n\n        num_iterations = self.num_iterations\n\n        for i in range(num_iterations):\n            probs = F.softmax(logits, dim=2)\n            outputs = self.squash((probs * priors).sum(dim=2, keepdim=True), dim=3)\n\n            if i != self.num_iterations - 1:\n                delta_logits = priors * outputs\n                logits = logits + delta_logits\n\n        # outputs[b, out_caps, 1, data_out, 1]\n        outputs = outputs.squeeze()\n\n        if len(outputs.shape) == 3:\n            outputs = outputs.transpose(2, 1).contiguous() \n        else:\n            outputs = outputs.unsqueeze_(dim=0).transpose(2, 1).contiguous()\n        # outputs[b, data_out, out_caps]\n\n        return outputs\n\n\nclass CapsuleNet(nn.Module):\n    def __init__(self, num_class, gpu_id):\n        super(CapsuleNet, self).__init__()\n\n        self.num_class = num_class\n        self.fea_ext = FeatureExtractor()\n        self.fea_ext.apply(self.weights_init)\n\n        self.routing_stats = RoutingLayer(gpu_id=gpu_id, num_input_capsules=NO_CAPS, num_output_capsules=num_class, data_in=8, data_out=4, num_iterations=2)\n\n    def weights_init(self, m):\n        classname = m.__class__.__name__\n        if classname.find('Conv') != -1:\n            m.weight.data.normal_(0.0, 0.02)\n        elif classname.find('BatchNorm') != -1:\n            m.weight.data.normal_(1.0, 0.02)\n            m.bias.data.fill_(0)\n\n    def forward(self, x, random=False, dropout=0.0):\n\n        z = self.fea_ext(x)\n        z = self.routing_stats(z, random, dropout=dropout)\n        # z[b, data, out_caps]\n\n        # classes = F.softmax(z, dim=-1)\n\n        # class_ = classes.detach()\n        # class_ = class_.mean(dim=1)\n\n        # return classes, class_\n\n        classes = F.softmax(z, dim=-1)\n        class_ = classes.detach()\n        class_ = class_.mean(dim=1)\n\n        return z, class_\n\n\nclass CapsuleLoss(nn.Module):\n    def __init__(self, gpu_id):\n        super(CapsuleLoss, self).__init__()\n        self.cross_entropy_loss = nn.CrossEntropyLoss()\n\n        if gpu_id >= 0:\n            self.cross_entropy_loss.cuda(gpu_id)\n\n    def forward(self, classes, labels):\n        loss_t = self.cross_entropy_loss(classes[:,0,:], labels)\n\n        for i in range(classes.size(1) - 1):\n            loss_t = loss_t + self.cross_entropy_loss(classes[:,i+1,:], labels)\n\n        return loss_t","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:22:46.979157Z","iopub.execute_input":"2025-06-12T06:22:46.979394Z","iopub.status.idle":"2025-06-12T06:22:54.795148Z","shell.execute_reply.started":"2025-06-12T06:22:46.979373Z","shell.execute_reply":"2025-06-12T06:22:54.794337Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import sys\nsys.setrecursionlimit(15000)\nimport os\nimport random\nimport torch\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nfrom torch.autograd import Variable\nfrom torch.optim import Adam\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\nimport argparse\nfrom sklearn import metrics\n\n\n# Hardcoded configuration values\ndataset = '/kaggle/input/splitframes-uadfv/split_data'  # Path to root dataset\ntrain_set = 'train'  # Train set\nval_set = 'val'  # Validation set\nworkers = 4 # Number of data loading workers\nbatchSize = 32  # Batch size\nimageSize = 300  # Input image size (height/width)\nniter = 25  # Number of epochs to train for\nlr = 0.0005  # Learning rate\nbeta1 = 0.9  # Beta1 for Adam optimizer\ngpu_id = 0  # GPU ID\nresume = 0  # Epoch to resume from (0 to train from scratch)\noutf = 'checkpoints/binary_faceforensicspp'  # Folder to output model checkpoints\ndisable_random = False  # Disable randomness for routing matrix\ndropout = 0.05  # Dropout percentage\nmanualSeed = None  # Manual seed\n\n# Print configuration for verification\nprint(f\"Dataset: {dataset}\")\nprint(f\"Train Set: {train_set}\")\nprint(f\"Validation Set: {val_set}\")\nprint(f\"Workers: {workers}\")\nprint(f\"Batch Size: {batchSize}\")\nprint(f\"Image Size: {imageSize}\")\nprint(f\"Epochs: {niter}\")\nprint(f\"Learning Rate: {lr}\")\nprint(f\"Beta1: {beta1}\")\nprint(f\"GPU ID: {gpu_id}\")\nprint(f\"Resume Epoch: {resume}\")\nprint(f\"Output Folder: {outf}\")\nprint(f\"Disable Random: {disable_random}\")\nprint(f\"Dropout: {dropout}\")\nprint(f\"Manual Seed: {manualSeed}\")\n\n# Set random seed\nif manualSeed is None:\n    manualSeed = random.randint(1, 10000)\nprint(f\"Random Seed: {manualSeed}\")\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)\n\nif gpu_id >= 0:\n    torch.cuda.manual_seed_all(manualSeed)\n    cudnn.benchmark = True\n\n# Create output directory if it doesn't exist\nos.makedirs(outf, exist_ok=True)\n\n# Open the CSV file for logging\nif resume > 0:\n    text_writer = open(os.path.join(outf, 'train.csv'), 'a')\nelse:\n    text_writer = open(os.path.join(outf, 'train.csv'), 'w')\n\n# Initialize model components\nvgg_ext = VggExtractor()\ncapnet = CapsuleNet(2, gpu_id)\ncapsule_loss = CapsuleLoss(gpu_id)\n\noptimizer = Adam(capnet.parameters(), lr=lr, betas=(beta1, 0.999))\n\n# Resume training if specified\nif resume > 0:\n    capnet.load_state_dict(torch.load(os.path.join(outf, f'capsule_{resume}.pt')))\n    capnet.train(mode=True)\n    optimizer.load_state_dict(torch.load(os.path.join(outf, f'optim_{resume}.pt')))\n\n    if gpu_id >= 0:\n        for state in optimizer.state.values():\n            for k, v in state.items():\n                if isinstance(v, torch.Tensor):\n                    state[k] = v.cuda(gpu_id)\n\n# Move models to GPU if specified\nif gpu_id >= 0:\n    capnet.cuda(gpu_id)\n    vgg_ext.cuda(gpu_id)\n    capsule_loss.cuda(gpu_id)\n\n# Define image transformations\ntransform_fwd = transforms.Compose([\n    transforms.Resize((imageSize, imageSize)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\n# Load datasets\ndataset_train = dset.ImageFolder(root=os.path.join(dataset, train_set), transform=transform_fwd)\nassert dataset_train, \"Train dataset not found!\"\ndataloader_train = torch.utils.data.DataLoader(dataset_train, batch_size=batchSize, shuffle=True, num_workers=workers)\n\ndataset_val = dset.ImageFolder(root=os.path.join(dataset, val_set), transform=transform_fwd)\nassert dataset_val, \"Validation dataset not found!\"\ndataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=batchSize, shuffle=False, num_workers=workers)\n\n# Training loop\nfor epoch in range(resume + 1, niter + 1):\n    count = 0\n    loss_train = 0\n    loss_test = 0\n\n    tol_label = np.array([], dtype=np.float64)\n    tol_pred = np.array([], dtype=np.float64)\n\n    for img_data, labels_data in tqdm(dataloader_train):\n        labels_data[labels_data > 1] = 1\n        img_label = labels_data.numpy().astype(np.float64)\n        optimizer.zero_grad()\n\n        if gpu_id >= 0:\n            img_data = img_data.cuda(gpu_id)\n            labels_data = labels_data.cuda(gpu_id)\n\n        input_v = Variable(img_data)\n        x = vgg_ext(input_v)\n        classes, class_ = capnet(x, random=not disable_random, dropout=dropout)\n\n        loss_dis = capsule_loss(classes, Variable(labels_data, requires_grad=False))\n        loss_dis_data = loss_dis.item()\n\n        loss_dis.backward()\n        optimizer.step()\n\n        output_dis = class_.data.cpu().numpy()\n        output_pred = np.zeros((output_dis.shape[0]), dtype=np.float64)\n\n        for i in range(output_dis.shape[0]):\n            if output_dis[i, 1] >= output_dis[i, 0]:\n                output_pred[i] = 1.0\n            else:\n                output_pred[i] = 0.0\n\n        tol_label = np.concatenate((tol_label, img_label))\n        tol_pred = np.concatenate((tol_pred, output_pred))\n\n        loss_train += loss_dis_data\n        count += 1\n\n    acc_train = metrics.accuracy_score(tol_label, tol_pred)\n    loss_train /= count\n\n    # Save model checkpoint\n    torch.save(capnet.state_dict(), os.path.join(outf, f'capsule_{epoch}.pt'))\n    torch.save(optimizer.state_dict(), os.path.join(outf, f'optim_{epoch}.pt'))\n\n    # Validation\n    capnet.eval()\n\n    tol_label = np.array([], dtype=np.float64)\n    tol_pred = np.array([], dtype=np.float64)\n\n    count = 0\n\n    for img_data, labels_data in dataloader_val:\n        labels_data[labels_data > 1] = 1\n        img_label = labels_data.numpy().astype(np.float64)\n\n        if gpu_id >= 0:\n            img_data = img_data.cuda(gpu_id)\n            labels_data = labels_data.cuda(gpu_id)\n\n        input_v = Variable(img_data)\n        x = vgg_ext(input_v)\n        classes, class_ = capnet(x, random=False)\n\n        loss_dis = capsule_loss(classes, Variable(labels_data, requires_grad=False))\n        loss_dis_data = loss_dis.item()\n        output_dis = class_.data.cpu().numpy()\n\n        output_pred = np.zeros((output_dis.shape[0]), dtype=np.float64)\n\n        for i in range(output_dis.shape[0]):\n            if output_dis[i, 1] >= output_dis[i, 0]:\n                output_pred[i] = 1.0\n            else:\n                output_pred[i] = 0.0\n\n        tol_label = np.concatenate((tol_label, img_label))\n        tol_pred = np.concatenate((tol_pred, output_pred))\n\n        loss_test += loss_dis_data\n        count += 1\n\n    acc_test = metrics.accuracy_score(tol_label, tol_pred)\n    loss_test /= count\n\n    print(f'[Epoch {epoch}] Train loss: {loss_train:.4f}   acc: {acc_train * 100:.2f} | Test loss: {loss_test:.4f}  acc: {acc_test * 100:.2f}')\n\n    text_writer.write(f'{epoch},{loss_train:.4f},{acc_train * 100:.2f},{loss_test:.4f},{acc_test * 100:.2f}\\n')\n    text_writer.flush()\n\n    capnet.train(mode=True)\n\ntext_writer.close()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:23:08.173810Z","iopub.execute_input":"2025-06-12T06:23:08.174084Z","iopub.status.idle":"2025-06-12T06:36:32.141039Z","shell.execute_reply.started":"2025-06-12T06:23:08.174062Z","shell.execute_reply":"2025-06-12T06:36:32.140012Z"}},"outputs":[{"name":"stdout","text":"Dataset: /kaggle/input/splitframes-uadfv/split_data\nTrain Set: train\nValidation Set: val\nWorkers: 4\nBatch Size: 32\nImage Size: 300\nEpochs: 25\nLearning Rate: 0.0005\nBeta1: 0.9\nGPU ID: 0\nResume Epoch: 0\nOutput Folder: checkpoints/binary_faceforensicspp\nDisable Random: False\nDropout: 0.05\nManual Seed: None\nRandom Seed: 2971\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n100%|██████████| 548M/548M [00:02<00:00, 210MB/s] \n100%|██████████| 68/68 [00:44<00:00,  1.53it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 1] Train loss: 1.8370   acc: 92.18 | Test loss: 1.8403  acc: 98.26\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 2] Train loss: 1.5613   acc: 97.67 | Test loss: 1.5428  acc: 98.70\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 3] Train loss: 1.5206   acc: 98.00 | Test loss: 1.5094  acc: 97.83\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 4] Train loss: 1.4970   acc: 98.09 | Test loss: 1.4711  acc: 98.48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 5] Train loss: 1.4777   acc: 98.19 | Test loss: 1.4689  acc: 97.61\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 6] Train loss: 1.4616   acc: 98.60 | Test loss: 1.4709  acc: 98.48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 7] Train loss: 1.4533   acc: 98.46 | Test loss: 1.4773  acc: 96.75\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 8] Train loss: 1.4404   acc: 98.42 | Test loss: 1.4227  acc: 98.48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 9] Train loss: 1.4193   acc: 98.84 | Test loss: 1.4523  acc: 96.53\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 10] Train loss: 1.4186   acc: 98.65 | Test loss: 1.9595  acc: 85.03\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 11] Train loss: 1.4358   acc: 98.46 | Test loss: 1.4362  acc: 96.75\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 12] Train loss: 1.4073   acc: 98.37 | Test loss: 1.4354  acc: 97.40\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 13] Train loss: 1.3834   acc: 99.12 | Test loss: 1.4075  acc: 98.48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 14] Train loss: 1.3821   acc: 98.84 | Test loss: 1.4347  acc: 96.53\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 15] Train loss: 1.3820   acc: 98.98 | Test loss: 1.3862  acc: 98.48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 16] Train loss: 1.3662   acc: 99.12 | Test loss: 1.3959  acc: 97.61\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 17] Train loss: 1.3741   acc: 98.98 | Test loss: 1.4205  acc: 97.40\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 18] Train loss: 1.3596   acc: 99.12 | Test loss: 1.3634  acc: 98.48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 19] Train loss: 1.3505   acc: 99.12 | Test loss: 1.3643  acc: 98.26\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 20] Train loss: 1.3451   acc: 99.30 | Test loss: 1.4034  acc: 97.18\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 21] Train loss: 1.3514   acc: 99.16 | Test loss: 1.3611  acc: 98.70\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 22] Train loss: 1.3422   acc: 99.30 | Test loss: 1.3593  acc: 98.70\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 23] Train loss: 1.3543   acc: 99.16 | Test loss: 1.3831  acc: 98.48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 24] Train loss: 1.3423   acc: 99.21 | Test loss: 1.3610  acc: 98.48\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 68/68 [00:28<00:00,  2.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"[Epoch 25] Train loss: 1.3381   acc: 99.26 | Test loss: 1.3932  acc: 97.61\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import os\nimport torch\nimport torch.backends.cudnn as cudnn\nimport numpy as np\nfrom torch.autograd import Variable\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nfrom tqdm import tqdm\nfrom sklearn import metrics\nfrom scipy.optimize import brentq\nfrom scipy.interpolate import interp1d\nfrom sklearn.metrics import roc_curve\n\n\n# Directly set the parameters (replace with your specific values)\ndataset = '/kaggle/input/splitframes-uadfv/split_data/'  # Path to dataset\ntest_set = 'test'  # Test set folder\nworkers = 0  # Number of data loading workers\nbatchSize = 32  # Batch size\nimageSize = 300  # Image height and width\ngpu_id = 0  # GPU ID\noutf = '/kaggle/working/checkpoints/binary_faceforensicspp'  # Folder for model checkpoints\nrandom = False  # Randomness for routing matrix\ncheckpoint_id = 21  # Checkpoint ID\n\n# Print the options\nprint(f\"Dataset: {dataset}\")\nprint(f\"Test set: {test_set}\")\nprint(f\"Batch size: {batchSize}\")\nprint(f\"Image size: {imageSize}\")\nprint(f\"GPU ID: {gpu_id}\")\nprint(f\"Output folder: {outf}\")\nprint(f\"Randomness enabled: {random}\")\nprint(f\"Checkpoint ID: {checkpoint_id}\")\n\n# Define the transform for images\ntransform_fwd = transforms.Compose([\n    transforms.Resize((imageSize, imageSize)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])\n\n# Load the test dataset\ndataset_test = dset.ImageFolder(root=os.path.join(dataset, test_set), transform=transform_fwd)\nassert dataset_test\ndataloader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batchSize, shuffle=False, num_workers=workers)\n\n# Load model components\nvgg_ext = VggExtractor()\ncapnet = CapsuleNet(2, gpu_id)\n\n# Load the checkpoint\ncapnet.load_state_dict(torch.load(os.path.join(outf, f'capsule_{checkpoint_id}.pt')))\ncapnet.eval()\n\n# Move models to GPU if available\nif gpu_id >= 0:\n    vgg_ext.cuda(gpu_id)\n    capnet.cuda(gpu_id)\n\n# Initialize arrays for storing results\ntol_label = np.array([], dtype=float)\ntol_pred = np.array([], dtype=float)\ntol_pred_prob = np.array([], dtype=float)\n\ncount = 0\nloss_test = 0\n\n# Open the text file to write results\nwith open(os.path.join(outf, 'test.txt'), 'w') as text_writer:\n    \n    for img_data, labels_data in tqdm(dataloader_test):\n        labels_data[labels_data > 1] = 1\n        img_label = labels_data.numpy().astype(float)\n\n        if gpu_id >= 0:\n            img_data = img_data.cuda(gpu_id)\n            labels_data = labels_data.cuda(gpu_id)\n\n        input_v = Variable(img_data)\n\n        x = vgg_ext(input_v)\n        classes, class_ = capnet(x, random=random)\n\n        output_dis = class_.data.cpu()\n        output_pred = np.zeros((output_dis.shape[0]), dtype=float)\n\n        for i in range(output_dis.shape[0]):\n            if output_dis[i, 1] >= output_dis[i, 0]:\n                output_pred[i] = 1.0\n            else:\n                output_pred[i] = 0.0\n\n        tol_label = np.concatenate((tol_label, img_label))\n        tol_pred = np.concatenate((tol_pred, output_pred))\n        \n        pred_prob = torch.softmax(output_dis, dim=1)\n        tol_pred_prob = np.concatenate((tol_pred_prob, pred_prob[:, 1].data.numpy()))\n\n        count += 1\n\n    # Calculate accuracy and EER\n    acc_test = metrics.accuracy_score(tol_label, tol_pred)\n    loss_test /= count\n\n    fpr, tpr, thresholds = roc_curve(tol_label, tol_pred_prob, pos_label=1)\n    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n\n    # Write results to text file\n    print(f'[Epoch {checkpoint_id}] Test acc: {acc_test*100:.2f}   EER: {eer*100:.2f}')\n    text_writer.write(f'{checkpoint_id},{acc_test*100:.2f},{eer*100:.2f}\\n')\n\n    # Flush and close the file\n    text_writer.flush()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T06:36:37.831498Z","iopub.execute_input":"2025-06-12T06:36:37.832559Z","iopub.status.idle":"2025-06-12T06:36:47.831765Z","shell.execute_reply.started":"2025-06-12T06:36:37.832528Z","shell.execute_reply":"2025-06-12T06:36:47.831028Z"}},"outputs":[{"name":"stdout","text":"Dataset: /kaggle/input/splitframes-uadfv/split_data/\nTest set: test\nBatch size: 32\nImage size: 300\nGPU ID: 0\nOutput folder: /kaggle/working/checkpoints/binary_faceforensicspp\nRandomness enabled: False\nCheckpoint ID: 21\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n100%|██████████| 15/15 [00:06<00:00,  2.17it/s]","output_type":"stream"},{"name":"stdout","text":"[Epoch 21] Test acc: 98.92   EER: 1.29\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":3}]}